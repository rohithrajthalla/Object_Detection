{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9dd1e72-46be-4b44-a9b3-ee5d890972e9",
   "metadata": {},
   "source": [
    "## Installing Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36ce8ba9-aa9b-4fca-86ab-9000b2f09625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python-headless in ./.local/lib/python3.8/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.19.3 in ./.local/lib/python3.8/site-packages (from opencv-python-headless) (1.24.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bf42353-4cc4-427d-a293-4b065dbec5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in ./.local/lib/python3.8/site-packages (1.12.0a0+2c916ef.nv22.3)\n",
      "Requirement already satisfied: torchvision in ./.local/lib/python3.8/site-packages/torchvision-0.13.0-py3.8-linux-aarch64.egg (0.13.0)\n",
      "Requirement already satisfied: typing-extensions in ./.local/lib/python3.8/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.8/site-packages (from torchvision) (1.24.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.30.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.local/lib/python3.8/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchvision) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->torchvision) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchvision) (2019.11.28)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "235ae5c2-8464-4da0-9252-3aef8557bb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: flask in ./.local/lib/python3.8/site-packages (3.0.3)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in ./.local/lib/python3.8/site-packages (from flask) (3.0.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.8/dist-packages (from flask) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in ./.local/lib/python3.8/site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in ./.local/lib/python3.8/site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in ./.local/lib/python3.8/site-packages (from flask) (1.8.2)\n",
      "Requirement already satisfied: importlib-metadata>=3.6.0 in ./.local/lib/python3.8/site-packages (from flask) (6.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in ./.local/lib/python3.8/site-packages (from importlib-metadata>=3.6.0->flask) (3.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.local/lib/python3.8/site-packages (from Jinja2>=3.1.2->flask) (2.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90b0d6cf-c856-4787-ae1a-06bbd2ecba03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyHS100 in ./.local/lib/python3.8/site-packages (0.3.5.2)\n",
      "Requirement already satisfied: click in ./.local/lib/python3.8/site-packages (from pyHS100) (8.1.7)\n",
      "Requirement already satisfied: click-datetime in ./.local/lib/python3.8/site-packages (from pyHS100) (0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyHS100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8a3fe0-4240-4552-81d5-434f27046f46",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3efff80-f061-49b3-8f5f-634f5f4f62c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, Response  # Import Flask framework for building web applications\n",
    "from pyHS100 import SmartPlug  # Import SmartPlug class for controlling TP-Link Smart Plugs\n",
    "import cv2  # Import OpenCV library for image and video processing\n",
    "import torch  # Import PyTorch library for deep learning\n",
    "import time  # Import time module for timing operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89899b64-4263-4c1f-87a6-11056cfcdcbf",
   "metadata": {},
   "source": [
    "## Testing Smart plug connection and control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "016c32e5-783d-4364-9e96-cf5cb89c822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IP address of our smart plug\n",
    "plug_ip = '10.0.0.125'\n",
    "\n",
    "# Establishing connection to our smart plug\n",
    "plug = SmartPlug(plug_ip)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c434c07d-92eb-4772-bb97-4b34e2712154",
   "metadata": {},
   "source": [
    "##### Turning smart plug on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e55876e-9a52-4bc3-a76d-6b26c4175bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plug.turn_on()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138fb7bc-3204-49d2-b890-1bd5f6e7e0b0",
   "metadata": {},
   "source": [
    "##### Turning smart plug off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7077cf5c-701c-4896-b0bf-e8307f8f1fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plug.turn_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c80498-336e-406c-9190-4a59bec3a4a0",
   "metadata": {},
   "source": [
    "## Object Detection with Smart Plug Control\n",
    "real-time object detection system using the YOLOv5 model. It captures video frames from a webcam, performs object detection to count the number of people in the frame, and displays the count on the video feed. Additionally, it controls a smart plug based on the number of people detected: turning the plug on when people are detected and off otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08eb951e-48dc-4deb-9476-4164e0e28b18",
   "metadata": {},
   "source": [
    "##### Initialize Flask and connect to smartplug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd5eb2dc-c9e0-4087-a7a9-7c83f3764485",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "plug_ip = '10.0.0.125'\n",
    "plug = SmartPlug(plug_ip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df61451d-3ad1-48d0-b9c0-eece292d4e9c",
   "metadata": {},
   "source": [
    "##### Load YOLOv5 model for object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e160cc89-8e0c-4504-9bbd-b7b4122ef21b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jetson/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2024-5-8 Python-3.8.10 torch-1.12.0a0+2c916ef.nv22.3 CUDA:0 (Orin, 7337MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1c1867-2a4e-4dca-bdf3-1a565733181e",
   "metadata": {},
   "source": [
    "##### Check if GPU is available, otherwise use CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45cc8d18-10e4-4ad7-9e82-ae901f875330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a820c2c4-04b9-4d6d-a5d1-ab018bba4294",
   "metadata": {},
   "source": [
    "##### Function to generate video frames with object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce3a3fa2-9b67-451d-ad57-d5c8d8c99fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_frames():\n",
    "    # Open the default camera for video capture\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        # Read a frame from the camera\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        start_time = time.time()  # Start time for overall frame processing\n",
    "\n",
    "        # Convert frame to RGB color space\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Perform object detection using the YOLOv5 model\n",
    "        gpu_start_time = time.time()  # Start time for inference\n",
    "        results = model(frame_rgb)\n",
    "        gpu_end_time = time.time()  # End time for inference\n",
    "        gpu_processing_time = gpu_end_time - gpu_start_time  # processing time\n",
    "\n",
    "        n_people = 0  # Initialize number of people detected\n",
    "        for det in results.xyxy[0]:\n",
    "            if int(det[5]) == 0:  # Check if the detected class is 'person'\n",
    "                n_people += 1  # Increment number of people detected\n",
    "                start_point = (int(det[0]), int(det[1]))  \n",
    "                end_point = (int(det[2]), int(det[3]))  \n",
    "                color = (255, 0, 0)  \n",
    "                thickness = 2\n",
    "                cv2.rectangle(frame, start_point, end_point, color, thickness) \n",
    "\n",
    "        # Add text to the frame showing number of people detected and processing time\n",
    "        cv2.putText(frame, f'People Count: {n_people}', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(frame, f'{device} Time: {gpu_processing_time:.3f} sec', (50, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Control smart plug based on number of people detected\n",
    "        if n_people > 0:\n",
    "            plug.turn_on()  \n",
    "        else:\n",
    "            plug.turn_off()  \n",
    "\n",
    "        end_time = time.time()  # End time for overall frame processing\n",
    "        processing_time = end_time - start_time  # Total processing time\n",
    "\n",
    "        # Encode frame as JPEG\n",
    "        ret, buffer = cv2.imencode('.jpg', frame)\n",
    "        frame = buffer.tobytes()\n",
    "\n",
    "        # Yield the frame for streaming\n",
    "        yield (b'--frame\\r\\n'\n",
    "               b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6ab24a-ff69-493d-a24a-29368c17a667",
   "metadata": {},
   "source": [
    "##### Route to stream the video feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15ce86d8-6b39-480b-9216-81b01cdc8245",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/video')\n",
    "def video():\n",
    "    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c26b0d-ac9a-453c-8d44-01d0c7fb737d",
   "metadata": {},
   "source": [
    "##### Main to run flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32b0bee-1ab7-4f9d-946c-207f730a5366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://10.0.0.66:5000\n",
      "Press CTRL+C to quit\n",
      "10.0.0.247 - - [08/May/2024 14:08:51] \"GET /video HTTP/1.1\" 200 -\n",
      "10.0.0.247 - - [08/May/2024 14:10:15] \"GET /video HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a60f0c-1a98-4ced-8556-2166194e054e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357d60f8-e273-48e4-9434-10f11bf36ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f3b8dc8-d5a2-49f3-8e2e-c2eadc57fabd",
   "metadata": {},
   "source": [
    "## Test with CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97400a67-d6f5-4695-a330-b0cfe108efda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, Response\n",
    "from pyHS100 import SmartPlug\n",
    "import cv2\n",
    "import torch\n",
    "import time\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "plug_ip = '10.0.0.125'\n",
    "plug = SmartPlug(plug_ip)\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True, force_reload=True)\n",
    "device = 'cpu'\n",
    "model.to(device)\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "def generate_frames():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        gpu_start_time = time.time()\n",
    "        results = model(frame_rgb)\n",
    "        gpu_end_time = time.time()\n",
    "        gpu_processing_time = gpu_end_time - gpu_start_time\n",
    "\n",
    "        n_people = 0\n",
    "        for det in results.xyxy[0]:\n",
    "            if int(det[5]) == 0:\n",
    "                n_people += 1\n",
    "                start_point = (int(det[0]), int(det[1]))\n",
    "                end_point = (int(det[2]), int(det[3]))\n",
    "                color = (255, 0, 0)\n",
    "                thickness = 2\n",
    "                cv2.rectangle(frame, start_point, end_point, color, thickness)\n",
    "\n",
    "        cv2.putText(frame, f'People Count: {n_people}', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        cv2.putText(frame, f'CPU Processing Time: {gpu_processing_time:.3f} sec', (50, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        if n_people > 0:\n",
    "            plug.turn_on()\n",
    "        else:\n",
    "            plug.turn_off()\n",
    "\n",
    "        end_time = time.time()\n",
    "        processing_time = end_time - start_time\n",
    "\n",
    "        ret, buffer = cv2.imencode('.jpg', frame)\n",
    "        frame = buffer.tobytes()\n",
    "\n",
    "        yield (b'--frame\\r\\n'\n",
    "               b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n",
    "\n",
    "@app.route('/video')\n",
    "def video():\n",
    "    return Response(generate_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4023b5-dcd0-476c-8a7c-d969112db78e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d6fe7c-6847-4cfb-bd40-7e98a42c471d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
